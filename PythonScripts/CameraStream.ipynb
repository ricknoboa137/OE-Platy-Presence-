{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0023bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erick\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, Response\n",
    "import cv2\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "def gen():\n",
    "    cap = cv2.VideoCapture(0)  # Capture video from webcam (device 0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        else:\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(gen(),\n",
    "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "700a66a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erick\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# this code captures video from an usb camera and cast it over LAN \n",
    "# it requires the file \"index.html\" inside the forlder /templates/ \n",
    "\n",
    "from flask import Flask, render_template, Response\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "def gen():\n",
    "    cap = cv2.VideoCapture(0)  # Capture video from webcam (device 0)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') #Load face detection model\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        else:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "            # Draw rectangle around the faces\n",
    "            for i, (x, y, w, h) in enumerate(faces):\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"Face {i+1}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\n",
    "            frame = buffer.tobytes()\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(gen(),\n",
    "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec633e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "#Encode the video into h264 format before streaming\n",
    "\n",
    "from flask import Flask, render_template, Response\n",
    "import av\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fourcc_type = 'avc1'\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "def gen():\n",
    "    # Create an AVStream for output\n",
    "    output = av.open('pipe:1', 'w')\n",
    "    stream = output.add_stream('libx264', 20)\n",
    "    stream.width = 640\n",
    "    stream.height = 480\n",
    "    stream.pix_fmt = 'yuv420p'\n",
    "\n",
    "    while True:\n",
    "        ret, frame = camera.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        else:\n",
    "            # Convert the image from BGR color space to YUV\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV_I420)\n",
    "\n",
    "            # Create an AVFrame and fill it with the YUV image\n",
    "            av_frame = av.VideoFrame.from_ndarray(frame, format='yuv420p')\n",
    "            av_frame.pts = None\n",
    "\n",
    "            # Encode the frame\n",
    "            for packet in stream.encode(av_frame):\n",
    "                output.mux(packet)\n",
    "\n",
    "            # Yield the encoded frame\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: video/x-h264\\r\\n\\r\\n' + packet.to_bytes() + b'\\r\\n')\n",
    "\n",
    "    # Flush the encoder and muxer\n",
    "    for packet in stream.encode():\n",
    "        output.mux(packet)\n",
    "\n",
    "    output.close()\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(gen(),\n",
    "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c51420d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidDataError",
     "evalue": "[Errno 1094995529] Invalid data found when processing input: '<none>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidDataError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24560\\3830048033.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Received unexpected status code {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mdecode_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24560\\3830048033.py\u001b[0m in \u001b[0;36mdecode_stream\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Create an AVContainer for input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mcontainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mav\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Get the video stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mav\\\\container\\\\core.pyx\u001b[0m in \u001b[0;36mav.container.core.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mav\\\\container\\\\core.pyx\u001b[0m in \u001b[0;36mav.container.core.Container.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mav\\\\container\\\\core.pyx\u001b[0m in \u001b[0;36mav.container.core.Container.err_check\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mav\\\\error.pyx\u001b[0m in \u001b[0;36mav.error.err_check\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mInvalidDataError\u001b[0m: [Errno 1094995529] Invalid data found when processing input: '<none>'"
     ]
    }
   ],
   "source": [
    "# To decode H.264 video stream \n",
    "import av\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "def decode_stream():\n",
    "    # Open the stream\n",
    "    r = requests.get('http://localhost:5000/video_feed', stream=True)\n",
    "\n",
    "    if(r.status_code == 200):\n",
    "        # Create an AVContainer for input\n",
    "        container = av.open(r.raw)\n",
    "\n",
    "        # Get the video stream\n",
    "        video_stream = next(s for s in container.streams if s.type == 'video')\n",
    "\n",
    "        for packet in container.demux(video_stream):\n",
    "            for frame in packet.decode():\n",
    "                # Convert the frame to RGB format\n",
    "                frame = frame.to_rgb().to_ndarray()\n",
    "\n",
    "                # Display the resulting frame\n",
    "                cv2.imshow('frame', frame)\n",
    "\n",
    "                # Break the loop on 'q' key press\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Received unexpected status code {}\".format(r.status_code))\n",
    "\n",
    "decode_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ce9f68",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (3213942129.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\erick\\AppData\\Local\\Temp\\ipykernel_24560\\3213942129.py\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    output = av.open('tcp://localhost:5554?listen=1', mode='w','mp4')\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "#Stream video using AV \n",
    "import cv2\n",
    "import av\n",
    "import numpy as np\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Unable to read camera feed\")\n",
    "\n",
    "# Default resolutions of the frame are obtained.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Create an AV stream\n",
    "output = av.open('tcp://localhost:5554?listen=1', mode='w','mp4')\n",
    "\n",
    "# Create a stream\n",
    "stream = output.add_stream('mpeg4', 30)\n",
    "stream.width = frame_width\n",
    "stream.height = frame_height\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the image to numpy array\n",
    "    frame = np.array(frame)\n",
    "\n",
    "    # Convert the numpy array to AVFrame\n",
    "    av_frame = av.VideoFrame.from_ndarray(frame, format='rgb24')\n",
    "\n",
    "    # Encode the frame\n",
    "    packets = stream.encode(av_frame)\n",
    "\n",
    "    # Write the packets\n",
    "    for packet in packets:\n",
    "        output.mux(packet)\n",
    "\n",
    "# Close the frames\n",
    "cap.release()\n",
    "\n",
    "# Close the AV stream\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd71b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d95a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = av.open('pipe:1', 'w','mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2126b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afea0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ZMQ TEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4063afe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -s SERVER_IP\n",
      "ipykernel_launcher.py: error: the following arguments are required: -s/--server-ip\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erick\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import imagezmq\n",
    "import argparse\n",
    "import socket\n",
    "import time\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-s\", \"--server-ip\", required=True,\n",
    "                help=\"ip address of the server to which the client will connect\")\n",
    "args = vars(ap.parse_args())\n",
    "# initialize the ImageSender object with the socket address of the\n",
    "# server\n",
    "sender = imagezmq.ImageSender(connect_to=\"tcp://{}:5555\".format(\n",
    "    args[\"server_ip\"]))\n",
    "# get the host name, initialize the video stream, and allow the\n",
    "# camera sensor to warmup\n",
    "rpiName = socket.gethostname()\n",
    "#vs = VideoStream(usePiCamera=True).start()\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    " \n",
    "while True:\n",
    "    # read the frame from the camera and send it to the server\n",
    "    frame = vs.read()\n",
    "    sender.send_image(rpiName, frame)\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e170f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f405309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import build_montages\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import imagezmq\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--prototxt\", required=True, \n",
    "                help=\"path to Caffe 'deploy' prototxt file\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "                help=\"path to Caffe pre-trained model\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.2,\n",
    "                help=\"minimum probability to filter weak detections\")\n",
    "ap.add_argument(\"-mW\", \"--montageW\", required=True, type=int,\n",
    "                help=\"montage frame width\")\n",
    "ap.add_argument(\"-mH\", \"--montageH\", required=True, type=int,\n",
    "                help=\"montage frame height\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# initialize the ImageHub object\n",
    "imageHub = imagezmq.ImageHub()\n",
    "# initialize the list of class labels MobileNet SSD was trained to\n",
    "# detect, then generate a set of bounding box colors for each class\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "           \"sofa\", \"train\", \"tvmonitor\"]\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])\n",
    "# initialize the consider set (class labels we care about and want\n",
    "# to count), the object count dictionary, and the frame  dictionary\n",
    "CONSIDER = set([\"dog\", \"person\", \"car\"])\n",
    "objCount = {obj: 0 for obj in CONSIDER}\n",
    "frameDict = {}\n",
    "# initialize the dictionary which will contain  information regarding\n",
    "# when a device was last active, then store the last time the check\n",
    "# was made was now\n",
    "lastActive = {}\n",
    "lastActiveCheck = datetime.now()\n",
    "# stores the estimated number of Pis, active checking period, and\n",
    "# calculates the duration seconds to wait before making a check to\n",
    "# see if a device was active\n",
    "ESTIMATED_NUM_PIS = 4\n",
    "ACTIVE_CHECK_PERIOD = 10\n",
    "ACTIVE_CHECK_SECONDS = ESTIMATED_NUM_PIS * ACTIVE_CHECK_PERIOD\n",
    "# assign montage width and height so we can view all incoming frames\n",
    "# in a single \"dashboard\"\n",
    "mW = args[\"montageW\"]\n",
    "mH = args[\"montageH\"]\n",
    "print(\"[INFO] detecting: {}...\".format(\", \".join(obj for obj in CONSIDER)))\n",
    "\n",
    "# start looping over all the frames\n",
    "while True:\n",
    "    # receive RPi name and frame from the RPi and acknowledge\n",
    "    # the receipt\n",
    "    (rpiName, frame) = imageHub.recv_image()\n",
    "    imageHub.send_reply(b'OK')\n",
    "    # if a device is not in the last active dictionary then it means\n",
    "    # that its a newly connected device\n",
    "    if rpiName not in lastActive.keys():\n",
    "        print(\"[INFO] receiving data from {}...\".format(rpiName))\n",
    "    # record the last active time for the device from which we just\n",
    "    # received a frame\n",
    "    lastActive[rpiName] = datetime.now()\n",
    "    \n",
    "    # resize the frame to have a maximum width of 400 pixels, then\n",
    "    # grab the frame dimensions and construct a blob\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), \n",
    "                                 0.007843, (300, 300), 127.5)\n",
    "    # pass the blob through the network and obtain the detections and\n",
    "    # predictions\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    # reset the object count for each object in the CONSIDER set\n",
    "    objCount = {obj: 0 for obj in CONSIDER}\n",
    "    \n",
    "    # loop over the detections\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with\n",
    "        # the prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        # filter out weak detections by ensuring the confidence is\n",
    "        # greater than the minimum confidence\n",
    "        if confidence > args[\"confidence\"]:\n",
    "            # extract the index of the class label from the\n",
    "            # detections\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "            # check to see if the predicted class is in the set of\n",
    "            # classes that need to be considered\n",
    "            if CLASSES[idx] in CONSIDER:\n",
    "                # increment the count of the particular object\n",
    "                # detected in the frame\n",
    "                objCount[CLASSES[idx]] += 1\n",
    "                # compute the (x, y)-coordinates of the bounding box\n",
    "                # for the object\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                # draw the bounding box around the detected object on\n",
    "                # the frame\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "                              (255, 0, 0), 2)\n",
    "                \n",
    "                                # draw the sending device name on the frame\n",
    "                cv2.putText(frame, rpiName, (10, 25),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                # draw the object count on the frame\n",
    "                label = \", \".join(\"{}: {}\".format(obj, count) for (obj, count) in\n",
    "                                  objCount.items())\n",
    "                cv2.putText(frame, label, (10, h - 20), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255,0), 2)\n",
    "                # update the new frame in the frame dictionary\n",
    "                frameDict[rpiName] = frame\n",
    "                # build a montage using images in the frame dictionary\n",
    "                montages = build_montages(frameDict.values(), (w, h), (mW, mH))\n",
    "                # display the montage(s) on the screen\n",
    "                for (i, montage) in enumerate(montages):\n",
    "                    cv2.imshow(\"Home pet location monitor ({})\".format(i), \n",
    "                               montage)\n",
    "                # detect any kepresses\n",
    "                key = cv2.waitKey(1) & 0xFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this program on each RPi to send a labelled image stream\n",
    "import socket\n",
    "import time\n",
    "from imutils.video import VideoStream\n",
    "import imagezmq\n",
    "\n",
    "sender = imagezmq.ImageSender(connect_to='tcp://localhost:5555')\n",
    "\n",
    "rpi_name = socket.gethostname() # send RPi hostname with each image\n",
    "print(rpi_name)\n",
    "picam = VideoStream(src=0).start()\n",
    "time.sleep(2.0)  # allow camera sensor to warm up\n",
    "while True:  # send images as stream until Ctrl-C\n",
    "    image = picam.read()\n",
    "    sender.send_image(rpi_name, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV client \n",
    "\n",
    "import cv2\n",
    "import imagezmq\n",
    "image_hub = imagezmq.ImageHub()\n",
    "while True:  # show streamed images until Ctrl-C\n",
    "    rpi_name, image = image_hub.recv_image()\n",
    "    cv2.imshow(rpi_name, image) # 1 window for each RPi\n",
    "    cv2.waitKey(1)\n",
    "    image_hub.send_reply(b'OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imagezmq\n",
    "\n",
    "# Initialize the ImageHub object\n",
    "image_hub = imagezmq.ImageHub()\n",
    "\n",
    "while True:\n",
    "    # Receive a frame from the client\n",
    "    client_name, frame = image_hub.recv_image()\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(client_name, frame)\n",
    "\n",
    "    # If the 'q' key is pressed, break from the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Send a reply to the client (necessary to continue the loop on the client side)\n",
    "    image_hub.send_reply(b'OK')\n",
    "\n",
    "# After the loop, close the display window\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98964255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imagezmq\n",
    "import socket\n",
    "import signal\n",
    "import time   # For the demo only\n",
    "\n",
    "def signal_handler(signal, frame):\n",
    "    global interrupted\n",
    "    interrupted = True\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "# Initialize the ImageSender object\n",
    "sender = imagezmq.ImageSender(connect_to='tcp://localhost:5555')\n",
    "\n",
    "# Assign a name to the client\n",
    "client_name = socket.gethostname() # send RPi hostname with each image\n",
    "print(client_name)\n",
    "\n",
    "# Initialize a VideoCapture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the VideoCapture object\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If a frame was successfully read...\n",
    "    if ret:\n",
    "        # Send the frame to the server\n",
    "        sender.send_image(client_name, frame)\n",
    "    \n",
    "    if interrupted:\n",
    "        print(\"Gotta go\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BARD VERSION WEBSOCKET TRANSMITIONS\n",
    "\n",
    "import cv2\n",
    "import socket\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# Define the IP address and port for broadcasting\n",
    "HOST = 'localhost'  # Replace with the receiving device's IP address\n",
    "PORT = 8000\n",
    "\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)  # 0 for the first webcam\n",
    "\n",
    "# Set the frame rate to 30 frames per second\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Define the output video file name\n",
    "output_filename = 'live_video.mp4'\n",
    "\n",
    "# Create a socket object for sending data over TCP\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "\n",
    "# Start the server and listen for incoming connections\n",
    "sock.bind((HOST, PORT))\n",
    "sock.listen(5)\n",
    "print(\"Server started and listening...\")\n",
    "\n",
    "# Create a thread to handle streaming to each client\n",
    "def handle_client(client_socket):\n",
    "    global cap, video_writer\n",
    "    try:\n",
    "        # Start the video writer if it hasn't been started already\n",
    "        if not video_writer:\n",
    "            video_writer = cv2.VideoWriter(output_filename, cv2.VideoWriter_fourcc(*'MP4V'), 30, (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "        # Continuously capture frames from the webcam and send them to the client\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert the frame to a NumPy array\n",
    "            data = frame.tobytes()\n",
    "\n",
    "            # Send the frame data to the client\n",
    "            client_socket.sendall(data)\n",
    "\n",
    "            # Write the frame to the MP4 file if it is greater than a specific size\n",
    "            if len(data) > 1024 * 1024:\n",
    "                # Write the current frame to the MP4 file\n",
    "                video_writer.write(frame)\n",
    "\n",
    "    except:\n",
    "        client_socket.close()\n",
    "\n",
    "# Accept incoming connections from clients\n",
    "while True:\n",
    "    try:\n",
    "        client_socket, address = sock.accept()\n",
    "        print(f\"Connected to client: {address}\")\n",
    "\n",
    "        # Create a new thread to handle streaming to this client\n",
    "        thread = threading.Thread(target=handle_client, args=(client_socket,))\n",
    "        thread.start()\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Close the video capture object and video writer\n",
    "cap.release()\n",
    "if video_writer:\n",
    "    video_writer.release()\n",
    "\n",
    "# Close the socket object\n",
    "sock.close()\n",
    "\n",
    "# Close the display window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf37295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting HTTP server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Dec/2023 18:34:26] \"GET /live_video.mp4 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Dec/2023 18:34:26] \"GET /live_video.mp4 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Dec/2023 18:37:41] \"GET /live_video.mp4 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Dec/2023 18:37:41] \"GET /live_video.mp4 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import socket\n",
    "import threading\n",
    "import time\n",
    "import base64\n",
    "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
    "\n",
    "# Define the IP address and port for broadcasting\n",
    "HOST = '192.168.0.116'  # Replace with the receiving device's IP address\n",
    "PORT = 8228\n",
    "\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)  # 0 for the first webcam\n",
    "\n",
    "# Set the frame rate to 30 frames per second\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Define the output video file name\n",
    "output_filename = 'live_video.mp4'\n",
    "\n",
    "# Class for handling HTTP requests\n",
    "class HTTPHandler(BaseHTTPRequestHandler):\n",
    "    def do_GET(self):\n",
    "        # Check if the requested path is the video stream\n",
    "        if self.path == '/live_video.mp4':\n",
    "            # Read the current frame from the webcam\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Convert the frame to a NumPy array\n",
    "            frame_data = frame.tobytes()\n",
    "\n",
    "            # Encode the frame data as base64\n",
    "            encoded_data = base64.b64encode(frame_data)\n",
    "\n",
    "            # Send the encoded frame data\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-Type', 'video/mp4')\n",
    "            self.end_headers()\n",
    "            self.wfile.write(encoded_data)\n",
    "            return\n",
    "\n",
    "        # Send error response if the requested path is invalid\n",
    "        self.send_error(404)\n",
    "        self.end_headers()\n",
    "\n",
    "\n",
    "# Create a TCP socket server for HTTP communication\n",
    "server = HTTPServer(('localhost', PORT), HTTPHandler)\n",
    "server.allow_reuse_address = True\n",
    "print(\"Starting HTTP server...\")\n",
    "server.serve_forever()\n",
    "\n",
    "\n",
    "# Start the HTTP server\n",
    "server_thread = threading.Thread(target=server.serve_forever)\n",
    "server_thread.daemon = True\n",
    "server_thread.start()\n",
    "\n",
    "# Continuously capture frames from the webcam and send them as HTTP requests\n",
    "while True:\n",
    "    # Read the current frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to a NumPy array\n",
    "    frame_data = frame.tobytes()\n",
    "\n",
    "    # Encode the frame data as base64\n",
    "    encoded_data = base64.b64encode(frame_data)\n",
    "\n",
    "    # Send the encoded frame data as an HTTP request\n",
    "    req = \"GET /live_video.mp4 HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\nContent-Length: {}\\r\\n\\r\\n{}\".format(len(encoded_data), encoded_data.decode())\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    sock.connect((HOST, PORT))\n",
    "    sock.sendall(req.encode())\n",
    "    sock.close()\n",
    "\n",
    "    # Write the frame to the MP4 file if it is greater than a specific size\n",
    "    if len(frame_data) > 1024 * 1024:\n",
    "        # Write the current frame to the MP4 file\n",
    "        video_writer = cv2.VideoWriter(output_filename, cv2.VideoWriter_fourcc(*'MP4V'), 30, (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "        video_writer.write(frame)\n",
    "\n",
    "# Close the video capture object and video writer\n",
    "cap.release()\n",
    "if video_writer:\n",
    "    video_writer.release()\n",
    "\n",
    "# Close the server thread\n",
    "server.server_close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc75f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "# Define the IP address and port of the Flask application\n",
    "HOST = '192.168.1.255'  # Replace with the Flask application's IP address\n",
    "PORT = 8080\n",
    "\n",
    "# Create a request object for the live video stream\n",
    "url = f'http://{HOST}:{PORT}/live_video.mp4'\n",
    "\n",
    "# Continuously fetch the live video stream and decode the base64 data\n",
    "while True:\n",
    "    # Send a GET request for the live video stream\n",
    "    response = requests.get(url).content\n",
    "\n",
    "    # Decode the base64 data into a NumPy array\n",
    "    decoded_data = base64.b64decode(response)\n",
    "\n",
    "    # Convert the NumPy array to a frame\n",
    "    frame = cv2.imdecode(np.frombuffer(decoded_data, dtype='uint8'), -1)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Received Video', frame)\n",
    "\n",
    "    # Check for the 'q' key to quit\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close the video stream\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e61fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2eeb5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17168\\209286770.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17168\\209286770.py\u001b[0m in \u001b[0;36mgen\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#ret, imgOriginalScene = cap.read()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://192.168.0.108:5000/video_feed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mimg_resp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mimg_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_resp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mimgOriginalScene\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    527\u001b[0m         }\n\u001b[0;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mcontent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    836\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m                 \u001b[0mflush_decoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[1;31m# StringIO doesn't like amt=None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from flask import Flask, render_template, Response\n",
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def gen():\n",
    "    #cap = cv2.VideoCapture(0)  # Capture video from webcam (device 0)\n",
    "    #ret, imgOriginalScene = cap.read()\n",
    "    url = \"http://192.168.0.108:5000/video_feed\"\n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    imgOriginalScene = cv2.imdecode(img_arr, -1)\n",
    "    cv2.imshow(\"IPcamera\", imgOriginalScene)\n",
    "    cv2.namedWindow('IPcamera', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('IPcamera', 300, 300)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2abe166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MQTT IMAGE TRANSMISSION\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import base64\n",
    "from paho.mqtt import client as mqtt_client\n",
    "import random\n",
    "\n",
    "\n",
    "# Define the IP address and port for broadcasting\n",
    "broker = '192.168.0.108'  # Broadcast to all devices on the network\n",
    "port = 1883\n",
    "topic = \"test\"\n",
    "\n",
    "\n",
    "# Generate a Client ID with the publish prefix.\n",
    "client_id = f'ImageProvider-{random.randint(0, 1000)}'\n",
    "# username = 'emqx'\n",
    "# password = 'public'\n",
    "\n",
    "################################################################################\n",
    "def connect_mqtt():\n",
    "    def on_connect(client, userdata, flags, rc):\n",
    "        if rc == 0:\n",
    "            print(\"Connected to MQTT Broker!\")\n",
    "        else:\n",
    "            print(\"Failed to connect, return code %d\\n\", rc)\n",
    "\n",
    "    client = mqtt_client.Client(client_id)\n",
    "    # client.username_pw_set(username, password)\n",
    "    client.on_connect = on_connect\n",
    "    client.connect(broker, port)\n",
    "    return client\n",
    "\n",
    "\n",
    "def publish(client, msg):\n",
    "    msg_count = 1\n",
    "    #print(msg)\n",
    "    result = client.publish(topic, msg) # result: [0, 1]\n",
    "    status = result[0]\n",
    "    if status == 0:\n",
    "        msg_count += 1\n",
    "        #print(\"Message Printed\")\n",
    "    else:\n",
    "        print(f\"Failed to send message to topic {topic}\")\n",
    "    \n",
    "    \n",
    "##################################################################################\n",
    "\n",
    "\n",
    "client = connect_mqtt()\n",
    "client.loop_start()\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)  # 0 for the first webcam\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') #Load face detection model\n",
    "# Set the frame rate to 30 frames per second\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 480)\n",
    "cont =1\n",
    "while cont == 1:\n",
    "    #cont =2\n",
    "    # Read the current frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
    "    \n",
    "    # Draw rectangle around the faces\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Face {i+1}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "    \n",
    "    resize= cv2.resize(frame, (1280, 480))\n",
    "    frame = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY)\n",
    "    #print(frame.shape)\n",
    "    res, frame = cv2.imencode('.jpg', frame)    # from image to binary buffer\n",
    "    \n",
    "    #print(frame)\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to a Base64 array\n",
    "    frame = base64.b64encode(frame) #frame.tobytes()\n",
    "    \n",
    "    # Send the encoded frame data as an Mqtt message\n",
    "    publish(client, frame)\n",
    "\n",
    "# Close the video capture object and video writer\n",
    "client.loop_stop()\n",
    "cap.release()\n",
    "\n",
    "###################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "220ba9f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "index = 0\n",
    "arr = []\n",
    "while True:\n",
    "    cap = cv2.VideoCapture(index)\n",
    "    if not cap.read()[0]:\n",
    "        break\n",
    "    else:\n",
    "        arr.append(index)\n",
    "    cap.release()\n",
    "    index += 1\n",
    "print( arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac15c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
